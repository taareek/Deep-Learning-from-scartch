{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n",
      "tensor([-0.0475, -0.1505, -0.1194, -0.0546,  0.1218, -0.0130,  0.1956,  0.1912,\n",
      "        -0.1198,  0.0043], grad_fn=<SelectBackward>)\n",
      "torch.Size([64])\n",
      "tensor(7)\n",
      "tensor(2.3083, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Building a Feed forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10))\n",
    "\n",
    "# Defining the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "#Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "print(images.shape)\n",
    "#Forward pass, get out logits\n",
    "logits = model(images)\n",
    "print(logits.shape)\n",
    "print(logits[3])\n",
    "print(labels.shape)\n",
    "print(labels[3])\n",
    "#Calculate the loss with the logits and labels\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Model with softmax output and calculate loss with negative log likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([-2.4237, -2.2963, -2.3095, -2.2999, -2.2693, -2.2493, -2.2412, -2.2660,\n",
      "        -2.3069, -2.3784], grad_fn=<SelectBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "my_model = nn.Sequential(nn.Linear(784,128),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(128,64),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(64,10),\n",
    "                         nn.LogSoftmax(dim =1))\n",
    "\n",
    "#Define the loss\n",
    "calculate_loss =  nn.NLLLoss()\n",
    "#Getting data\n",
    "images, labels = next(iter(trainloader))\n",
    "#Flatten the images\n",
    "images = images.view(images.shape[0], -1)\n",
    "#Forward pass, get output with log-softmax\n",
    "logits_2  = my_model(images)\n",
    "print(logits_2.shape)\n",
    "print(logits_2[2])\n",
    "# Calculating the loss using log likelihood loss function\n",
    "loss_2 = calculate_loss(logits_2, labels)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autograd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, requires_grad = True)\n",
    "with torch.no_grad():\n",
    "    y = x*2\n",
    "print(y)\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you can turn on or off gradients altogether with torch.set_grad_enabled(True|False).\n",
    "The gradients are computed with respect to some variable z with z.backward(). This does a backward pass through the operations that created z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6172,  0.0769],\n",
      "        [ 0.2620,  0.4664]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad = True)\n",
    "print(x)\n",
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3810, 0.0059],\n",
      "        [0.0686, 0.2175]], grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1683, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-cd4c40187c02>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(y.grad)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3086,  0.0385],\n",
      "        [ 0.1310,  0.2332]])\n",
      "tensor([[-0.3086,  0.0385],\n",
      "        [ 0.1310,  0.2332]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-3.5889e-04, -3.5889e-04, -3.5889e-04,  ..., -3.5889e-04,\n",
      "         -3.5889e-04, -3.5889e-04],\n",
      "        [-2.1071e-03, -2.1071e-03, -2.1071e-03,  ..., -2.1071e-03,\n",
      "         -2.1071e-03, -2.1071e-03],\n",
      "        [ 2.9162e-03,  2.9162e-03,  2.9162e-03,  ...,  2.9162e-03,\n",
      "          2.9162e-03,  2.9162e-03],\n",
      "        ...,\n",
      "        [-3.6813e-03, -3.6813e-03, -3.6813e-03,  ..., -3.6813e-03,\n",
      "         -3.6813e-03, -3.6813e-03],\n",
      "        [ 3.5215e-03,  3.5215e-03,  3.5215e-03,  ...,  3.5215e-03,\n",
      "          3.5215e-03,  3.5215e-03],\n",
      "        [-3.2476e-05, -3.2476e-05, -3.2476e-05,  ..., -3.2476e-05,\n",
      "         -3.2476e-05, -3.2476e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:  Parameter containing:\n",
      "tensor([[ 3.0601e-02, -1.2803e-02,  2.4131e-03,  ..., -2.7497e-02,\n",
      "         -3.3211e-05,  2.9672e-03],\n",
      "        [ 2.9511e-02,  2.5504e-02, -2.3023e-02,  ..., -2.4637e-02,\n",
      "         -2.3107e-02,  3.2171e-02],\n",
      "        [ 2.4239e-02, -2.2799e-02, -8.2576e-03,  ...,  1.9451e-02,\n",
      "          2.5680e-02, -2.3160e-02],\n",
      "        ...,\n",
      "        [-2.8293e-02, -2.6967e-02, -2.1232e-02,  ...,  9.1056e-03,\n",
      "          2.2899e-02,  1.4649e-03],\n",
      "        [ 9.1891e-03, -2.9866e-02, -3.2119e-02,  ..., -2.2340e-02,\n",
      "         -1.7779e-02,  1.0249e-02],\n",
      "        [-3.1128e-02, -1.2170e-02,  1.4823e-02,  ...,  1.8353e-02,\n",
      "          2.9773e-02,  1.4765e-02]], requires_grad=True)\n",
      "Loss:  tensor(2.3262, grad_fn=<NllLossBackward>)\n",
      "Gradient:  tensor([[ 0.0028,  0.0028,  0.0028,  ...,  0.0028,  0.0028,  0.0028],\n",
      "        [ 0.0040,  0.0040,  0.0040,  ...,  0.0040,  0.0040,  0.0040],\n",
      "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0021,  0.0021,  0.0021],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0018,  0.0018,  0.0018],\n",
      "        [-0.0019, -0.0019, -0.0019,  ..., -0.0019, -0.0019, -0.0019]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights: ', model[0].weight)\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64,784)\n",
    "#print(images[1].shape)\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "print('Loss: ', loss)\n",
    "loss.backward()\n",
    "print('Gradient: ', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights:  Parameter containing:\n",
      "tensor([[ 3.0572e-02, -1.2831e-02,  2.3847e-03,  ..., -2.7525e-02,\n",
      "         -6.1573e-05,  2.9389e-03],\n",
      "        [ 2.9470e-02,  2.5464e-02, -2.3063e-02,  ..., -2.4678e-02,\n",
      "         -2.3147e-02,  3.2131e-02],\n",
      "        [ 2.4218e-02, -2.2820e-02, -8.2788e-03,  ...,  1.9430e-02,\n",
      "          2.5659e-02, -2.3181e-02],\n",
      "        ...,\n",
      "        [-2.8299e-02, -2.6973e-02, -2.1237e-02,  ...,  9.1000e-03,\n",
      "          2.2893e-02,  1.4592e-03],\n",
      "        [ 9.1707e-03, -2.9885e-02, -3.2138e-02,  ..., -2.2359e-02,\n",
      "         -1.7797e-02,  1.0230e-02],\n",
      "        [-3.1109e-02, -1.2151e-02,  1.4842e-02,  ...,  1.8372e-02,\n",
      "          2.9792e-02,  1.4783e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights: ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1.9194586048248226\n",
      "Training loss:  0.8813012041834626\n",
      "Training loss:  0.5401082318951326\n",
      "Training loss:  0.4375562591752264\n",
      "Training loss:  0.39022570665774825\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #Flatten MNIST images into a 784 vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        #Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print('Training loss: ', running_loss/len(trainloader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[12].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
